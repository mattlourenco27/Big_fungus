{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"68c38ee7-cbd2-4609-a187-5e3fa49c013f","deepnote":{},"deepnote_execution_queue":[{"cellId":"00009-e9339e04-970c-42cc-814a-1834961c5bc9","sessionId":"4ec1462b-02fc-421b-a4c6-0232f9a0881d","msgId":"048b6ee7-1333-4a41-ab6c-170b36cf7497"},{"cellId":"00010-3d498406-4f2b-4b2c-98ec-792790b3fe22","sessionId":"4ec1462b-02fc-421b-a4c6-0232f9a0881d","msgId":"3e3f80bc-e618-4a71-a3fd-f1f4a75f074d"}],"colab":{"name":"ResNet152-Unfreeze.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"37bbcec9","execution_millis":1158,"id":"LnKVL0_hNhJJ","cell_id":"00000-238b35b7-fdda-452a-8734-1ed986b224f7","execution_start":1613897117828,"deepnote_cell_type":"code"},"source":["# Useful imports\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n","import torchvision.transforms as transforms\n","import torchvision.models\n","import matplotlib.pyplot as plt\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DfYyncNyV81A","executionInfo":{"status":"ok","timestamp":1617744252694,"user_tz":240,"elapsed":28483,"user":{"displayName":"Jun Ho Sung","photoUrl":"","userId":"14480476226923223622"}},"outputId":"ea228356-87bc-4166-c9da-c62a334078e7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2xkjDmk3UOA2"},"source":["!unzip /content/drive/MyDrive/APS360_Project/Mushaugm2.zip -d /root/Mushaugm2\n","!unzip /content/drive/MyDrive/APS360_Project/Mush_val.zip -d /root/Mush_val\n","!unzip /content/drive/MyDrive/APS360_Project/Mush_test.zip -d /root/Mush_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"23d6d6e7","execution_millis":4,"id":"mrZKT7eZNhJN","cell_id":"00001-4e5101ac-6d0c-4181-b237-faf4af49ef50","execution_start":1613897118989,"deepnote_cell_type":"code"},"source":["# Pytorch seed for reproducable results\n","torch.manual_seed(1000)\n","torch.set_deterministic(True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"76adaa8","execution_millis":3,"id":"Mb3gjh1UNhJN","cell_id":"00002-74e3575f-4e0b-472c-b74b-d28f9849cf52","execution_start":1613897119001,"deepnote_cell_type":"code"},"source":["# Get dataloader for the train, validation, and test set\n","def get_data_loader(batch_size):\n","    # Normalize images to the range [-1, 1]\n","    transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    # Load Dataset\n","    # Load Dataset\n","    # path = '/root/Mushfixs'\n","    # dataset = torchvision.datasets.ImageFolder(path, transform=transform)\n","    dataset_train = torchvision.datasets.ImageFolder('/root/Mushaugm2', transform=transform)\n","    dataset_val = torchvision.datasets.ImageFolder('/root/Mush_val', transform=transform)\n","    dataset_test = torchvision.datasets.ImageFolder('/root/Mush_test', transform=transform)\n","    \n","    # # Split into train, validation, and test sets\n","    # num_images = len(dataset)\n","    # train_len, val_len = int(0.7 * num_images), int(0.2 * num_images)\n","    # test_len = num_images - train_len - val_len\n","\n","    # train_data, val_data, test_data = random_split(\n","    #     dataset,\n","    #     [train_len, val_len, test_len],\n","    #     generator=torch.Generator()\n","    # )\n","    \n","    # Create dataloaders\n","    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n","    # train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    # val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n","    # test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n","    return train_loader, val_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"92c58961","execution_millis":422,"id":"la0HxaVgNhJN","cell_id":"00004-a46c3329-8929-4c5d-b213-464d3d3f749f","execution_start":1613897119007,"deepnote_cell_type":"code"},"source":["# Verify that the dataloader works\n","#train_loader, val_loader, test_loader = get_data_loader(batch_size = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"48bf96af","execution_millis":298,"id":"Az7Z-EnsNhJO","cell_id":"00005-165ec0b9-efff-4131-9de0-33f037cce054","execution_start":1613897119434,"deepnote_cell_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617744271417,"user_tz":240,"elapsed":47188,"user":{"displayName":"Jun Ho Sung","photoUrl":"","userId":"14480476226923223622"}},"outputId":"c085edfd-797b-4c88-a2bd-5cde8566f741"},"source":["# Download a pretrained ResNet-152 net model\n","ResNet = torchvision.models.resnet152(pretrained=True, progress=False)\n","modules = list(ResNet.children())[:-1] # delete the last fc layer.\n","#num_ftrs = ResNet.fc.in_features\n","\n","ResNetCL = nn.Sequential(*modules)\n","## Now set requires_grad to false\n","# for param in ResNetCL.parameters():\n","#     param.requires_grad = False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00005-e5c5df46-618d-4812-bf65-9d4d1eba9f6c","deepnote_to_be_reexecuted":false,"source_hash":"88659068","execution_millis":100,"execution_start":1613897119737,"deepnote_cell_type":"code","id":"aReUTrJcyawR"},"source":["# check the dimension of the output of\n","# test, labels = next(iter(train_loader))\n","# print(test.shape)\n","# test = ResNetCL(test)\n","# print(test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"f0fdeb3d","execution_millis":1,"id":"U8UjBgcBNhJP","cell_id":"00007-2584685d-a563-4478-adca-350d7c953d25","execution_start":1613897119839,"deepnote_cell_type":"code"},"source":["# Fully connected model\n","class ClassyMush(nn.Module):\n","    def __init__(self):\n","        super(ClassyMush, self).__init__()\n","        self.fc1 = nn.Linear(2048, 512)\n","        self.fc2 = nn.Linear(512, 9)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 2048*1*1) #flatten feature data\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        x = x.squeeze(1)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"9a55dc5f","execution_millis":2,"id":"aDs1V0IrNhJP","cell_id":"00008-c792a3c7-6b57-40d2-97b2-c4f57722f95d","execution_start":1613897119857,"deepnote_cell_type":"code"},"source":["# Define training and accuracy functions\n","def get_accuracy(model, cnn_model, loader):\n","    model.eval()\n","    cnn_model.eval()\n","    \n","    correct = 0\n","    total = 0\n","    for imgs, labels in loader:\n","        if use_cuda and torch.cuda.is_available():\n","            imgs = imgs.cuda()\n","            labels = labels.cuda()\n","\n","        output = model(cnn_model(imgs))\n","        \n","        #select index with maximum prediction score\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += imgs.shape[0]\n","\n","        if use_cuda and torch.cuda.is_available():\n","            imgs.to('cpu')\n","            labels.to('cpu')\n","\n","\n","\n","    return correct / total\n","\n","# Calculate the accuracy quikly during training\n","def quick_accuracy(model, cnn_model, loader):\n","  imgs, labels = next(iter(loader))\n","  \n","  #############################################\n","  #To Enable GPU Usage\n","  if use_cuda and torch.cuda.is_available():\n","    imgs = imgs.cuda()\n","    labels = labels.cuda()\n","  #############################################\n","\n","  output = model(cnn_model(imgs))\n","  \n","  #select index with maximum prediction score\n","  pred = output.max(1, keepdim=True)[1]\n","  correct = pred.eq(labels.view_as(pred)).sum().item()\n","  total = imgs.shape[0]\n","  \n","  if use_cuda and torch.cuda.is_available():\n","    imgs.to('cpu')\n","    labels.to('cpu')\n","\n","  # Only take the first batch for an accuracy approximation\n","  return correct / total\n","\n","def get_model_name(batch_size, learning_rate, num_epochs):\n","    path = \"ResNet_bs{}_lr{}_ne{}\".format(batch_size, learning_rate, num_epochs)\n","    return path\n","\n","def train_net(train_loader, val_loader, net, cnn_model, batch_size=64, learning_rate=0.01, num_epochs=30, save_after=100):\n","    # Cross Entropy loss criterion\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # Stochastic Gradient Descent\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","    \n","    # Use lists to track accuracy and loss\n","    iters, losses, train_acc, val_acc = [], [], [], []\n","\n","\n","    # Highest Validation accuracy for saving\n","    max_acc = 0\n","    save_path = \"/content/drive/MyDrive/APS360_Project/resnet152_states/Jun_Ho/unfreeze/\"\n","    model_path = get_model_name(batch_size, learning_rate, num_epochs)\n","    model_path = save_path + model_path\n","\n","\n","    # training\n","    start_time = time.time()\n","    n = 0 # the number of iterations\n","    for epoch in range(num_epochs):\n","        for images, labels in iter(train_loader):\n","            \n","            if use_cuda and torch.cuda.is_available():\n","                images = images.cuda()\n","                labels = labels.cuda()\n","            \n","            mid = cnn_model(images).detach()\n","            \n","\n","            out = net(mid)                      # forward pass\n","            loss = criterion(out, labels)       # compute the total loss\n","            loss.backward()                     # backward pass (compute parameter updates)\n","            optimizer.step()                    # make the updates for each parameter\n","            optimizer.zero_grad()               # a clean up step for PyTorch\n","\n","            ### save the current training information ###\n","            # only save every few iterations\n","            if n % 3 == 0:\n","\n","                # Iteration index\n","                iters.append(n)\n","\n","                # average loss\n","                losses.append(float(loss)/batch_size)\n","\n","                # compute quick validation accuracy\n","                val_acc.append(quick_accuracy(net, cnn_model, val_loader))\n","                \n","                # compute quick training accuracy \n","                pred = out.max(1, keepdim=True)[1]\n","                correct = pred.eq(labels.view_as(pred)).sum().item()\n","                total = images.shape[0]\n","                train_acc.append(correct / total)\n","                #print(\"Iteration:\", n)\n","            \n","            n += 1\n","            #print(\"Iteration:\", n)\n","\n","\n","            # move everything back to cpu \n","            if use_cuda and torch.cuda.is_available():\n","                images = images.to('cpu')\n","                labels = labels.to('cpu')\n","\n","            #######################################################\n","            # Only save if improved, but after 200 iterations because in the beginning it will always save\n","            if val_acc[-1] > max_acc and n > save_after:\n","                print(\"Found better, saving at epoch {} | iter {} - Validation accuracy: {:.2f}%\".format(epoch+1, n+1, val_acc[-1]*100))\n","                max_acc = val_acc[-1]\n","                \n","                # Save the current model (checkpoint) to a file\n","                torch.save(net.state_dict(), model_path + \".pt\")\n","                torch.save(cnn_model.state_dict(), model_path + \"_ResNet.pt\")\n","                ############################################\n","\n","\n","        print((\"Epoch {} Iter {}: Train acc: {} |\"+\n","                \" Validation acc: {} | loss: {}\").format(epoch + 1, n + 1,\n","                train_acc[-1], val_acc[-1], losses[-1]))\n","        \n","\n","    # Load and save state!\n","    net.load_state_dict(torch.load(model_path + \".pt\"))\n","    cnn_model.load_state_dict(torch.load(model_path + \"_ResNet.pt\"))\n","\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n","    \n","    # Write the train/val err and loss into CSV file for plotting later\n","    np.savetxt(\"{}_data.csv\".format(model_path), [iters, losses,\n","                                                  train_acc, val_acc])\n","\n","    return cnn_model, net\n","\n","def plot_training_curve(path):\n","    iters, losses, train_acc, val_acc = np.loadtxt(\"{}_data.csv\".format(path))\n","    \n","    # plotting\n","    plt.subplot(1, 1, 1)\n","    plt.title(\"Loss Curve\")\n","    plt.plot(iters, losses, label=\"Train\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Loss\")\n","\n","    plt.subplot(1, 1, 1)\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, train_acc, label=\"Train\")\n","    plt.plot(iters, val_acc, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EdPMA6nUz3hO","executionInfo":{"status":"ok","timestamp":1617744282539,"user_tz":240,"elapsed":58295,"user":{"displayName":"Jun Ho Sung","photoUrl":"","userId":"14480476226923223622"}},"outputId":"02719748-2570-46ef-ddc8-b667bb9ba1e7"},"source":["# Initialize model\n","use_cuda = True;\n","if use_cuda and torch.cuda.is_available():\n","    print(\"Selecting GPU...\")\n","    net = ClassyMush().cuda()\n","    modules = list(ResNet.children())[:-1] # delete the last fc layer.\n","    ResNetCL = nn.Sequential(*modules)\n","    ResNetCL = ResNetCL.cuda()\n","\n","    ct = 0\n","    for param in ResNetCL.parameters():\n","        ct += 1\n","        if ct <= 146:\n","          param.requires_grad = False\n","\n","else:\n","    net = ClassyMush()\n","    modules = list(ResNet.children())[:-1] # delete the last fc layer.\n","    ResNetCL = nn.Sequential(*modules)\n","    ### Now set requires_grad to false\n","    ct = 0\n","    for param in ResNetCL.parameters():\n","        ct += 1\n","        if ct <= 146:\n","          param.requires_grad = False\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selecting GPU...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DxuUZWcUnLRX"},"source":["bs = 64\n","lr = 0.001\n","ne = 100\n","sa = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"deepnote_to_be_reexecuted":false,"source_hash":"a8e6a68f","execution_millis":539991,"id":"ECkGjPx3NhJQ","cell_id":"00009-e9339e04-970c-42cc-814a-1834961c5bc9","execution_start":1613897119866,"deepnote_cell_type":"code"},"source":["# Get loaders for the training, validation, and test sets\n","train_loader, val_loader, test_loader = get_data_loader(bs)\n","\n","NewResNetCL, NewNet = train_net(train_loader, val_loader, net, ResNetCL, batch_size=bs, learning_rate=lr, num_epochs=ne, save_after=sa)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lzaEkUiBpfxI"},"source":["save_path = \"/content/drive/MyDrive/APS360_Project/resnet152_states/Jun_Ho/unfreeze/\"\n","path = get_model_name(bs, lr, ne)\n","plot_training_curve(save_path + path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LovP-d1qlLrN","cell_id":"00010-3d498406-4f2b-4b2c-98ec-792790b3fe22","deepnote_to_be_reexecuted":true,"source_hash":"3ab52778","deepnote_cell_type":"code"},"source":["# Test accuracy\n","use_cuda = True\n","\n","train_loader, val_loader, test_loader = get_data_loader(1)\n","\n","print('Finished Training')\n","print('Final accuracy: training: {:.2f} | validation: {:.2f}'.format(\n","    get_accuracy(NewNet, ResNetCL, train_loader),\n","    get_accuracy(NewNet, ResNetCL, val_loader)\n","))\n","\n","get_accuracy(NewNet, ResNetCL, test_loader)\n","\n","torch.save(NewNet.state_dict(), model_path + \".pt\")\n","torch.save(ResNetCL.state_dict(), model_path + \"_ResNet.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMSlOMQuifhM"},"source":["plot_training_curve(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6eDLMjhApex"},"source":["ResNetCL.to('cpu')\n","net.to('cpu')\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]}]}